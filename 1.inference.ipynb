{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICT, INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, SegformerForSemanticSegmentation\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import shutil\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define input/output paths\n",
    "UNLABELED_IMAGES_DIR = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/crooped_ortho_png\")\n",
    "CROPPED_ORTHO_IMG_DIR = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/cropped_ortho/\")\n",
    "\n",
    "PREDICTION_TIFF_OUTPUT_DIR = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/predictions_tiff\")\n",
    "if PREDICTION_TIFF_OUTPUT_DIR.exists():\n",
    "    shutil.rmtree(PREDICTION_TIFF_OUTPUT_DIR)\n",
    "PREDICTION_TIFF_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MERGED_PREDICTIONS_FOLDER = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/merged_predictions\")\n",
    "if MERGED_PREDICTIONS_FOLDER.exists():\n",
    "    shutil.rmtree(MERGED_PREDICTIONS_FOLDER)\n",
    "MERGED_PREDICTIONS_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "# Load model and processor\n",
    "MODEL_PATH = \"./segmentation_model/checkpoint-3807/\"\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "processor = AutoImageProcessor.from_pretrained(\"nvidia/mit-b0\", do_reduce_labels=False)\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(DEVICE)\n",
    "    return image, inputs\n",
    "\n",
    "# Function to perform inference\n",
    "def predict_mask(image_path):\n",
    "    image, inputs = preprocess_image(image_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits  # Shape: (1, num_labels, height, width)\n",
    "    mask_resized_bilinear = nn.functional.interpolate( # Segformer size is 1/4 need to resize to get mask on image\n",
    "            logits,  \n",
    "            size=image.size, \n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "    mask_resized_bilinear = mask_resized_bilinear.argmax(dim=1)[0].cpu().numpy().astype(np.uint8)\n",
    "    return mask_resized_bilinear + 1\n",
    "\n",
    "# Process all images\n",
    "\n",
    "\n",
    "def process_inference(session_images_path: Path, predictions_output_dir: Path, merged_predictions_dir: Path):\n",
    "\n",
    "    session_images = sorted(list(session_images_path.iterdir()))\n",
    "    predicted_rasters = []\n",
    "    for img_path in tqdm(session_images, desc=\"Processing images\"):\n",
    "        mask = predict_mask(img_path)\n",
    "        \n",
    "        # Store predicted mask for TIFF conversion\n",
    "        predicted_rasters.append((mask, img_path))\n",
    "\n",
    "    # Convert predictions to GeoTIFF using corresponding spatial info\n",
    "    for mask, img_path in tqdm(predicted_rasters):\n",
    "        corresponding_tiff = Path(CROPPED_ORTHO_IMG_DIR, session_images_path.name ,f\"{img_path.stem}.tif\")\n",
    "        if not corresponding_tiff.exists():\n",
    "            print(f\"Warning: No matching TIFF file found for {img_path.name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        with rasterio.open(corresponding_tiff) as src:\n",
    "            meta = src.meta.copy()\n",
    "            meta.update({\"dtype\": 'uint8', \"count\": 1, \"nodata\": 255}) \n",
    "            \n",
    "            output_tiff_path = Path(predictions_output_dir, f\"{img_path.stem}_prediction.tif\")\n",
    "            with rasterio.open(output_tiff_path, 'w', **meta) as dst:\n",
    "                mask = np.where(mask == 0, 255, mask)\n",
    "                dst.write(mask, 1)\n",
    "\n",
    "    # Merge all TIFF predictions into a single raster\n",
    "    merged_tiff_path = Path(merged_predictions_dir, f\"{session_images_path.name}_merged_predictions.tif\")\n",
    "    prediction_tiff_files = sorted(list(predictions_output_dir.iterdir()))\n",
    "\n",
    "    # Open all raster tiles\n",
    "    src_files_to_mosaic = [rasterio.open(f) for f in prediction_tiff_files]\n",
    "\n",
    "    # Step 1: Find min and max values dynamically\n",
    "    global_min, global_max = np.inf, -np.inf\n",
    "\n",
    "    for src in tqdm(src_files_to_mosaic, desc=\"Analyzing raster values\", unit=\"file\"):\n",
    "        tile_min, tile_max = src.read(1).min(), src.read(1).max()\n",
    "        global_min = min(global_min, tile_min)\n",
    "        global_max = max(global_max, tile_max)\n",
    "\n",
    "    # Ensure valid class range\n",
    "    num_classes = int(global_max - global_min + 1)\n",
    "    print(f\"✅ Detected class range: {global_min} to {global_max} ({num_classes} classes)\")\n",
    "\n",
    "    # Step 2: Merge rasters to determine full-size shape and transform\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic, method=\"first\") # Method is callable\n",
    "\n",
    "    # Step 3: Initialize a count array (num_classes layers, same size as mosaic)\n",
    "    value_counts = np.zeros((num_classes, mosaic.shape[1], mosaic.shape[2]), dtype=np.ubyte)\n",
    "\n",
    "    # Step 4: Process each tile and correctly map its values into the full raster\n",
    "    for src in tqdm(src_files_to_mosaic, desc=\"Processing tiles\", unit=\"file\"):\n",
    "        tile_data = src.read(1)  # Read first band\n",
    "        tile_transform = src.transform  # Get tile transform\n",
    "\n",
    "        # Compute tile window in the full raster\n",
    "        window = rasterio.windows.from_bounds(*src.bounds, transform=out_trans)\n",
    "        window = window.round_offsets().round_lengths()\n",
    "        row_off, col_off = int(window.row_off), int(window.col_off)\n",
    "        print(row_off, col_off)\n",
    "        return\n",
    "\n",
    "        # Place values into the full raster count array\n",
    "        for v in range(global_min, global_max + 1):  # Iterate over detected classes\n",
    "            value_counts[v - global_min, row_off:row_off + tile_data.shape[0], col_off:col_off + tile_data.shape[1]] += (tile_data == v)\n",
    "    return\n",
    "\n",
    "    # Step 5: Determine the most common value for each pixel\n",
    "    most_common_values = np.argmax(value_counts, axis=0) + global_min  # Convert index back to actual value\n",
    "\n",
    "    # Step 6: Handle NoData pixels\n",
    "    valid_pixel_mask = value_counts.sum(axis=0) > 0  # Check if at least one value exists\n",
    "\n",
    "    final_raster = np.where(valid_pixel_mask, most_common_values, 0)  # Set NoData pixels to 0\n",
    "\n",
    "    # Step 7: Save the final raster at `merged_tiff_path`\n",
    "    with rasterio.open(\n",
    "        merged_tiff_path,  # ✅ Corrected to save in merged_tiff_path\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=final_raster.shape[0],\n",
    "        width=final_raster.shape[1],\n",
    "        count=1,  # Single-band output\n",
    "        dtype=np.uint8,\n",
    "        crs=src_files_to_mosaic[0].crs,\n",
    "        transform=out_trans,\n",
    "        nodata=0  # Explicitly set NoData to 0\n",
    "    ) as dst:\n",
    "        dst.write(final_raster, 1)\n",
    "\n",
    "    # Step 8: Print summary\n",
    "    print(f\"✅ Merged raster saved at {merged_tiff_path}\")\n",
    "\n",
    "\n",
    "for session in sorted(list(UNLABELED_IMAGES_DIR.iterdir()))[1:2]:\n",
    "    prediction_dir_output = Path(PREDICTION_TIFF_OUTPUT_DIR, session.name)\n",
    "    prediction_dir_output.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "    process_inference(session, prediction_dir_output, MERGED_PREDICTIONS_FOLDER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Utiliser l'ortho de chateaux pour faire des tests :\n",
    "- Refaire avec le workflow normale\n",
    "- Refaire en sauvegardant values_count sans faire le argmax\n",
    "- Deamnder à matteo c'est ou que ses rasters se mergent proprement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, SegformerForSemanticSegmentation\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.transform import Affine\n",
    "import shutil\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define input/output paths\n",
    "UNLABELED_IMAGES_DIR = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/crooped_ortho_png\")\n",
    "CROPPED_ORTHO_IMG_DIR = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/cropped_ortho/\")\n",
    "\n",
    "PREDICTION_TIFF_OUTPUT_DIR = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/predictions_tiff\")\n",
    "if PREDICTION_TIFF_OUTPUT_DIR.exists():\n",
    "    shutil.rmtree(PREDICTION_TIFF_OUTPUT_DIR)\n",
    "PREDICTION_TIFF_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MERGED_PREDICTIONS_FOLDER = Path(\"/home/bioeos/Documents/project_hub/segment_upscaling/output/merged_predictions\")\n",
    "if MERGED_PREDICTIONS_FOLDER.exists():\n",
    "    shutil.rmtree(MERGED_PREDICTIONS_FOLDER)\n",
    "MERGED_PREDICTIONS_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Load model and processor\n",
    "MODEL_PATH = \"./segmentation_model/checkpoint-3807/\"\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "processor = AutoImageProcessor.from_pretrained(\"nvidia/mit-b0\", do_reduce_labels=False)\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(DEVICE)\n",
    "    return image, inputs\n",
    "\n",
    "# Function to perform inference\n",
    "def predict_mask(image_path):\n",
    "    image, inputs = preprocess_image(image_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits  # Shape: (1, num_labels, height, width)\n",
    "    mask_resized_bilinear = nn.functional.interpolate( # Segformer size is 1/4 need to resize to get mask on image\n",
    "            logits,  \n",
    "            size=image.size, \n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "    mask_resized_bilinear = mask_resized_bilinear.argmax(dim=1)[0].cpu().numpy().astype(np.uint8)\n",
    "    return mask_resized_bilinear + 1\n",
    "\n",
    "\n",
    "# Process all images\n",
    "def process_inference(session_images_path: Path, predictions_output_dir: Path, merged_predictions_dir: Path):\n",
    "    session_images = sorted(list(session_images_path.iterdir()))\n",
    "    predicted_rasters = []\n",
    "    \n",
    "    for img_path in tqdm(session_images, desc=\"Processing images\"):\n",
    "        mask = predict_mask(img_path)\n",
    "        predicted_rasters.append((mask, img_path))\n",
    "\n",
    "    # Convert predictions to GeoTIFF\n",
    "    for mask, img_path in tqdm(predicted_rasters):\n",
    "        corresponding_tiff = Path(CROPPED_ORTHO_IMG_DIR, session_images_path.name, f\"{img_path.stem}.tif\")\n",
    "        if not corresponding_tiff.exists():\n",
    "            print(f\"Warning: No matching TIFF file found for {img_path.name}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        with rasterio.open(corresponding_tiff) as src:\n",
    "            meta = src.meta.copy()\n",
    "            meta.update({\"dtype\": 'uint8', \"count\": 1, \"nodata\": 255}) \n",
    "            \n",
    "            output_tiff_path = Path(predictions_output_dir, f\"{img_path.stem}_prediction.tif\")\n",
    "            with rasterio.open(output_tiff_path, 'w', **meta) as dst:\n",
    "                mask = np.where(mask == 0, 255, mask)\n",
    "                dst.write(mask, 1)\n",
    "\n",
    "    # Merge all TIFF predictions into a single raster\n",
    "    merged_tiff_path = Path(merged_predictions_dir, f\"{session_images_path.name}_merged_predictions.tif\")\n",
    "    prediction_tiff_files = sorted(list(predictions_output_dir.iterdir()))\n",
    "    src_files_to_mosaic = [rasterio.open(f) for f in prediction_tiff_files]\n",
    "\n",
    "    # Min-max detection in a single pass\n",
    "    global_min, global_max = np.inf, -np.inf\n",
    "    for src in tqdm(src_files_to_mosaic, desc=\"Analyzing raster values\", unit=\"file\"):\n",
    "        tile = src.read(1)\n",
    "        global_min = min(global_min, tile.min())\n",
    "        global_max = max(global_max, tile.max())\n",
    "\n",
    "    num_classes = int(global_max - global_min + 1)\n",
    "    print(f\"✅ Detected class range: {global_min} to {global_max} ({num_classes} classes)\")\n",
    "\n",
    "    # Merge rasters\n",
    "    origin_mosaic, orig_transform = merge(src_files_to_mosaic, method=\"first\")\n",
    "\n",
    "    # Get the total size of the mosaic\n",
    "    height, width = origin_mosaic.shape[1], origin_mosaic.shape[2]\n",
    "\n",
    "    # Define the tile size\n",
    "    tile_size = 20000  \n",
    "    # Loop through and extract tiles\n",
    "    mosaic_tiles = []\n",
    "    for i in range(0, height, tile_size):\n",
    "        # Define the window, making sure it doesn't exceed bounds\n",
    "        win_height = min(tile_size, height - i)\n",
    "\n",
    "        # Extract the tile\n",
    "        tile = origin_mosaic[:, i:i+win_height, :]\n",
    "        mosaic_tiles.append((tile, i))  # Store tile with position\n",
    "\n",
    "    tiles_with_transforms = []\n",
    "    for tile, i in mosaic_tiles:\n",
    "        # Compute new transform for the tile\n",
    "        new_transform = orig_transform * Affine.translation(1, i)\n",
    "        tiles_with_transforms.append((tile, new_transform))\n",
    "\n",
    "    tmp_rasters = []\n",
    "    for i, (mosaic, out_trans) in enumerate(tiles_with_transforms):\n",
    "        tmp_path = Path(merged_predictions_dir, f\"{i}_{session_images_path.name}_merged_predictions.tif\") \n",
    "        # Optimized Argmax Calculation\n",
    "        most_common_values = np.full(mosaic.shape[1:], 0, dtype=np.uint8)  # Default to 0 (NoData)\n",
    "\n",
    "        count_buffer = np.zeros((num_classes, *mosaic.shape[1:]), dtype=np.uint16)  # Avoid large int types\n",
    "\n",
    "        for src in tqdm(src_files_to_mosaic, desc=\"Processing tiles\", unit=\"file\"):\n",
    "            tile_data = src.read(1)\n",
    "            window = rasterio.windows.from_bounds(*src.bounds, transform=out_trans).round_offsets().round_lengths()\n",
    "            \n",
    "             # Get offsets\n",
    "            row_off, col_off = int(window.row_off), int(window.col_off)\n",
    "\n",
    "            # **Handle Negative Offsets** (for overlapping images)\n",
    "            row_start_tile = max(0, -row_off)  # How much to crop from tile (if it's above raster)\n",
    "            col_start_tile = max(0, -col_off)\n",
    "\n",
    "            row_off = max(0, row_off)  # Adjust offset to fit inside mosaic\n",
    "            col_off = max(0, col_off)\n",
    "\n",
    "            row_end = min(row_off + tile_data.shape[0] - row_start_tile, most_common_values.shape[0])\n",
    "            col_end = min(col_off + tile_data.shape[1] - col_start_tile, most_common_values.shape[1])\n",
    "\n",
    "            tile_height = row_end - row_off\n",
    "            tile_width = col_end - col_off\n",
    "\n",
    "            if tile_height <= 0 or tile_width <= 0:\n",
    "                continue  # Skip tiles that are completely outside\n",
    "\n",
    "            # **Crop tile_data properly for out-of-bounds cases**\n",
    "            tile_data = tile_data[row_start_tile:row_start_tile + tile_height, col_start_tile:col_start_tile + tile_width]\n",
    "\n",
    "            # Update class frequencies, ensuring bounds are correct\n",
    "            for v in range(global_min, global_max + 1):\n",
    "                mask = (tile_data == v)  \n",
    "                count_buffer[v - global_min, row_off:row_end, col_off:col_end] += mask\n",
    "\n",
    "        # Faster argmax using efficient NumPy operations\n",
    "        valid_pixel_mask = count_buffer.sum(axis=0) > 0  # Avoid unnecessary computation\n",
    "        most_common_values[valid_pixel_mask] = count_buffer[:, valid_pixel_mask].argmax(axis=0) + global_min\n",
    "\n",
    "        # Save merged raster\n",
    "        with rasterio.open(\n",
    "            tmp_path,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=most_common_values.shape[0],\n",
    "            width=most_common_values.shape[1],\n",
    "            count=1,\n",
    "            dtype=np.uint8,\n",
    "            crs=src_files_to_mosaic[0].crs,\n",
    "            transform=out_trans,\n",
    "            compress=\"LZW\",\n",
    "            nodata=0,\n",
    "        ) as dst:\n",
    "            dst.write(most_common_values, 1)\n",
    "\n",
    "        tmp_rasters.append(tmp_path)\n",
    "\n",
    "    # Merge all the small tiles into a single large raster using rasterio.merge\n",
    "    mosaic, out_trans = merge([rasterio.open(tiff) for tiff in sorted(tmp_rasters)], method=\"first\")\n",
    "\n",
    "    # Save the final merged raster\n",
    "    with rasterio.open(\n",
    "        merged_tiff_path,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=mosaic.shape[1],\n",
    "        width=mosaic.shape[2],\n",
    "        count=1,\n",
    "        dtype=np.uint8,\n",
    "        crs=src.crs,\n",
    "        transform=out_trans,\n",
    "        compress=\"LZW\",\n",
    "        nodata=0\n",
    "    ) as dst:\n",
    "        dst.write(mosaic[0, :], 1)\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for temp_tiff in tmp_rasters:\n",
    "        temp_tiff.unlink()\n",
    "\n",
    "\n",
    "    print(f\"✅ Merged raster saved at {merged_tiff_path}\")\n",
    "\n",
    "for session in sorted(list(UNLABELED_IMAGES_DIR.iterdir()))[:6]:\n",
    "    prediction_dir_output = Path(PREDICTION_TIFF_OUTPUT_DIR, session.name)\n",
    "    prediction_dir_output.mkdir(exist_ok=True)\n",
    "    process_inference(session, prediction_dir_output, MERGED_PREDICTIONS_FOLDER)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drone_inference_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
